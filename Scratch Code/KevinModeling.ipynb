{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4540b6d1-c6e1-4bb8-84d3-9d137f2afba5",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259c011-fd0a-496f-b723-b8267074c532",
   "metadata": {},
   "source": [
    "In this notebook we perform our unsupervised modeling using the Non-negative Matrix Factorization (NMF), Latent Semantic Analysis (LSA), and Latent Dirichlet Allocation (LDA) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9ccbeec-d4da-42b7-a8b4-e05522a0f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab4ce17-a298-430d-990a-9ec578343ba4",
   "metadata": {},
   "source": [
    "We start by loading the cleaned data that we performed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0201b789-e2db-4804-9694-85e16866365d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/12/politics/cq-bro...</td>\n",
       "      <td>Chairman of the Joint Chiefs of Staff Gen. CQ ...</td>\n",
       "      <td>['chairman', 'joint', 'chiefs', 'staff', 'gen'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/12/politics/trump-...</td>\n",
       "      <td>Trump has endorsed North Carolina Republican P...</td>\n",
       "      <td>['trump', 'endorsed', 'north', 'carolina', 're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/12/politics/senate...</td>\n",
       "      <td>The Senate is inching closer to final passage ...</td>\n",
       "      <td>['senate', 'inching', 'closer', 'final', 'pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/12/politics/bidens...</td>\n",
       "      <td>Biden and King Abdullah II of Jordan met Monda...</td>\n",
       "      <td>['biden', 'king', 'abdullah', 'ii', 'jordan', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/12/politics/trump-...</td>\n",
       "      <td>Trump on Monday asked the SupremeCourt to step...</td>\n",
       "      <td>['trump', 'monday', 'asked', 'supremecourt', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                                url  \\\n",
       "0    cnn  https://www.cnn.com/2024/02/12/politics/cq-bro...   \n",
       "1    cnn  https://www.cnn.com/2024/02/12/politics/trump-...   \n",
       "2    cnn  https://www.cnn.com/2024/02/12/politics/senate...   \n",
       "3    cnn  https://www.cnn.com/2024/02/12/politics/bidens...   \n",
       "4    cnn  https://www.cnn.com/2024/02/12/politics/trump-...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Chairman of the Joint Chiefs of Staff Gen. CQ ...   \n",
       "1  Trump has endorsed North Carolina Republican P...   \n",
       "2  The Senate is inching closer to final passage ...   \n",
       "3  Biden and King Abdullah II of Jordan met Monda...   \n",
       "4  Trump on Monday asked the SupremeCourt to step...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['chairman', 'joint', 'chiefs', 'staff', 'gen'...  \n",
       "1  ['trump', 'endorsed', 'north', 'carolina', 're...  \n",
       "2  ['senate', 'inching', 'closer', 'final', 'pass...  \n",
       "3  ['biden', 'king', 'abdullah', 'ii', 'jordan', ...  \n",
       "4  ['trump', 'monday', 'asked', 'supremecourt', '...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned data\n",
    "cleaned_df = pd.read_csv('MSADS509_News_Project_Dataset/cleaned.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59511a68-70e2-48de-be3e-d6c2f4812db6",
   "metadata": {},
   "source": [
    "Now we split it up by source since our goal is to do a topic analysis of CNN and Fox News separately then compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd55ac4e-571e-4c74-95b6-73789c66e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up the cleaned DataFrame by source\n",
    "cnn_df = cleaned_df[cleaned_df['source'] == 'cnn']\n",
    "foxnews_df = cleaned_df[cleaned_df['source'] == 'foxnews']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6be208-750f-4f29-9bba-d172697e9210",
   "metadata": {},
   "source": [
    "### NMF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c60342-ccdc-49e8-a6aa-2f9e6527b6f2",
   "metadata": {},
   "source": [
    "We need to start by converting the text into a numerical format using Term Frequency-Inverse Document Frequency (TF-IDF) vectorization to make it suitable for the NMF model. We will perform TF-IDF on the \"content\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2257a274-c1c3-41a1-8519-f692a330c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79abc53e-fd29-4406-bdcf-f4c75e346ffd",
   "metadata": {},
   "source": [
    "Next, we start with CNN and fit the tfidf vectorizer on the content column. We retrieve the top five topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21f520fe-afc7-4c0d-832c-71ace4e6cdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Topics:\n",
      "Topic 1:\n",
      "democrat republican trump suozzi voter\n",
      "Topic 2:\n",
      "trump case trial court supremecourt\n",
      "Topic 3:\n",
      "nato trump defense spending alliance\n",
      "Topic 4:\n",
      "biden hur classified report documents\n",
      "Topic 5:\n",
      "ukraine aid senate border republican\n"
     ]
    }
   ],
   "source": [
    "# Process and display topics for CNN\n",
    "tfidf_cnn = tfidf_vectorizer.fit_transform(cnn_df['content'])\n",
    "nmf_model_cnn = NMF(n_components=5, random_state=42).fit(tfidf_cnn)\n",
    "tfidf_feature_names_cnn = tfidf_vectorizer.get_feature_names_out()\n",
    "print(\"CNN Topics:\")\n",
    "display_topics(nmf_model_cnn, tfidf_feature_names_cnn, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc10b99-5349-401a-b929-dcde457147e6",
   "metadata": {},
   "source": [
    "Next, we perform the analysis of the NMF model on the Fox News data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5421c82-0afe-4e65-8d67-972551d4feb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fox News Topics:\n",
      "Topic 1:\n",
      "house border senate republican aid\n",
      "Topic 2:\n",
      "bobulinski biden hunterbiden business family\n",
      "Topic 3:\n",
      "read trump campaign trail biden\n",
      "Topic 4:\n",
      "biden hur president special counsel\n",
      "Topic 5:\n",
      "trump nato alliance putin russia\n"
     ]
    }
   ],
   "source": [
    "# Process and display topics for Fox News\n",
    "tfidf_foxnews = tfidf_vectorizer.fit_transform(foxnews_df['content'])\n",
    "nmf_model_foxnews = NMF(n_components=5, random_state=42).fit(tfidf_foxnews)\n",
    "tfidf_feature_names_foxnews = tfidf_vectorizer.get_feature_names_out()\n",
    "print(\"\\nFox News Topics:\")\n",
    "display_topics(nmf_model_foxnews, tfidf_feature_names_foxnews, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c3ccdd-a728-4af4-b155-c3be076cf502",
   "metadata": {},
   "source": [
    "### LSA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f887e3e-9429-4896-8d05-3956fdb5ff99",
   "metadata": {},
   "source": [
    "We will use the same TF-IDF Vectorization we performed, and set up the LSA model on it. We will use the TruncatedSVD, which works for LSA modeling. We will also reinitialize the TF-IDF and reapply it to the CNN and Fox data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ca7e101-c9d8-4689-84b7-cd0c03033f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize the TF-IDF Vectorizer and apply it to both subsets again for clarity\n",
    "tfidf_vectorizer_cnn = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf_cnn = tfidf_vectorizer_cnn.fit_transform(cnn_df['content'])\n",
    "tfidf_feature_names_cnn = tfidf_vectorizer_cnn.get_feature_names_out()\n",
    "\n",
    "tfidf_vectorizer_foxnews = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf_foxnews = tfidf_vectorizer_foxnews.fit_transform(foxnews_df['content'])\n",
    "tfidf_feature_names_foxnews = tfidf_vectorizer_foxnews.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c24bd4c-78f3-4dbd-808c-7b14791f000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Truncated SVD for LSA on the TF-IDF matrices\n",
    "lsa_model_cnn = TruncatedSVD(n_components=5, random_state=42)\n",
    "lsa_cnn = lsa_model_cnn.fit_transform(tfidf_cnn)\n",
    "\n",
    "lsa_model_foxnews = TruncatedSVD(n_components=5, random_state=42)\n",
    "lsa_foxnews = lsa_model_foxnews.fit_transform(tfidf_foxnews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c65ea512-3548-4417-bb5b-9c5944a3e046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Topics for CNN:\n",
      "Topic 1:\n",
      "trump biden said republican election\n",
      "Topic 2:\n",
      "trump case trial willis court\n",
      "Topic 3:\n",
      "nato ukraine russia trump defense\n",
      "Topic 4:\n",
      "hur biden classified report documents\n",
      "Topic 5:\n",
      "ukraine aid willis case border\n"
     ]
    }
   ],
   "source": [
    "# Function to display topics for LSA (using Truncated SVD components)\n",
    "def display_topics_svd(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx + 1}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6467cb9c-f7ad-42e9-953c-7b7018d3e3b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Topics for CNN:\n",
      "Topic 1:\n",
      "trump biden said republican election\n",
      "Topic 2:\n",
      "trump case trial willis court\n",
      "Topic 3:\n",
      "nato ukraine russia trump defense\n",
      "Topic 4:\n",
      "hur biden classified report documents\n",
      "Topic 5:\n",
      "ukraine aid willis case border\n"
     ]
    }
   ],
   "source": [
    "# Display LSA Topics for CNN\n",
    "print(\"LSA Topics for CNN:\")\n",
    "display_topics_svd(lsa_model_cnn, tfidf_feature_names_cnn, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11e53cf9-6f19-432d-82ce-f3e21c15b131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSA Topics for Fox News:\n",
      "Topic 1:\n",
      "biden read trump bobulinski house\n",
      "Topic 2:\n",
      "bobulinski hunterbiden biden business family\n",
      "Topic 3:\n",
      "read biden counsel hur trail\n",
      "Topic 4:\n",
      "hur biden president memory report\n",
      "Topic 5:\n",
      "trump nato read bobulinski alliance\n"
     ]
    }
   ],
   "source": [
    "# Display LSA Topics for Fox News\n",
    "print(\"\\nLSA Topics for Fox News:\")\n",
    "display_topics_svd(lsa_model_foxnews, tfidf_feature_names_foxnews, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d51b3-e23b-4e97-91ad-bc77c3ddbf8e",
   "metadata": {},
   "source": [
    "### LDA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6c679-8a82-4e2d-8df1-2e6ca311303a",
   "metadata": {},
   "source": [
    "Next, we set up the LDA (Latent Dirichlet Allocation) model. This will require a different vectorization process. Unlike LSA and NMF, which both use TF-IDF, LDA uses count data. Therefore, we will use CountVectorizer from sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416919e4-7ebb-471e-8491-724c36d32737",
   "metadata": {},
   "source": [
    "We will start by initializing the CountVectorizer and declaring the number of topics we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c091c8a0-ec68-4a3c-be00-23559252dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "\n",
    "# Number of topics\n",
    "n_topics_lda = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784ba06-a6cb-429a-9abb-af80cb5ad276",
   "metadata": {},
   "source": [
    "Next, we will do one news organization at a time, beginning with CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d78c8ecd-c9af-46ca-af0d-1e7adc95ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the vectorizer to the 'content' column for CNN\n",
    "count_cnn = count_vectorizer.fit_transform(cnn_df['content'])\n",
    "\n",
    "# Get the feature names (words)\n",
    "count_feature_names_cnn = count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92cc4baf-a5a3-4871-b926-06bf4af5cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the LDA model to the CNN data\n",
    "lda_model_cnn = LatentDirichletAllocation(n_components=n_topics_lda, random_state=42)\n",
    "lda_cnn = lda_model_cnn.fit_transform(count_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebf4cffa-ff89-4e9c-9469-79c2a5f9a2f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics for CNN:\n",
      "Topic 1:\n",
      "trump said nato biden house\n",
      "Topic 2:\n",
      "democrat trump republican senate biden\n",
      "Topic 3:\n",
      "said intelligence cnn turner statement\n",
      "Topic 4:\n",
      "biden trump said president voter\n",
      "Topic 5:\n",
      "trump election case newyork said\n"
     ]
    }
   ],
   "source": [
    "# Display LDA Topics for CNN\n",
    "print(\"LDA Topics for CNN:\")\n",
    "display_topics_svd(lda_model_cnn, count_feature_names_cnn, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db66c8d6-27e3-4875-9cba-ed8cb0ee5a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA Topics for Fox News:\n",
      "Topic 1:\n",
      "biden president trump house special\n",
      "Topic 2:\n",
      "house said border senate security\n",
      "Topic 3:\n",
      "biden bobulinski hunterbiden business said\n",
      "Topic 4:\n",
      "trump said president sen ukraine\n",
      "Topic 5:\n",
      "read trump biden republican special\n"
     ]
    }
   ],
   "source": [
    "# Apply the vectorizer to the 'content' column for Fox News\n",
    "count_foxnews = count_vectorizer.fit_transform(foxnews_df['content'])\n",
    "\n",
    "# Get the feature names (words)\n",
    "count_feature_names_foxnews = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Initialize and fit the LDA model to the Fox News data\n",
    "lda_model_foxnews = LatentDirichletAllocation(n_components=n_topics_lda, random_state=42)\n",
    "lda_foxnews = lda_model_foxnews.fit_transform(count_foxnews)\n",
    "\n",
    "# Display LDA Topics for Fox News\n",
    "print(\"\\nLDA Topics for Fox News:\")\n",
    "display_topics_svd(lda_model_foxnews, count_feature_names_foxnews, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
